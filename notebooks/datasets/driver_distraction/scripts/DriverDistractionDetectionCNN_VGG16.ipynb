{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "\n",
    "from keras import backend\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Conv2D, Input, Lambda\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriverDistractionHelper:\n",
    "    \n",
    "    def __init__(self, img_rows, img_cols, color_type=1):\n",
    "        x_train, y_train, driver_id, unique_drivers = self.read_and_normalize_train_data(img_rows, img_cols, color_type)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=4484, random_state=57, stratify=y_train)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=4484, random_state=57, stratify=y_train)\n",
    "        \n",
    "        self.x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test.transpose(0, 2, 3, 1)\n",
    "        self.y_test = y_test\n",
    "        self.x_val = x_val.transpose(0, 2, 3, 1)\n",
    "        self.y_val = y_val\n",
    "    \n",
    "    def read_and_normalize_train_data(self, img_rows, img_cols, color_type):\n",
    "        cache_path = os.path.join('cache', 'train_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "        if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "            x_train, y_train, driver_id, unique_drivers = self.load_train(img_rows, img_cols, color_type)\n",
    "            self.cache_data((x_train, y_train, driver_id, unique_drivers), cache_path)\n",
    "        else:\n",
    "            print('Restore train from cache!')\n",
    "            (x_train, train_target, driver_id, unique_drivers) = restore_data(cache_path)\n",
    "\n",
    "        x_train = np.array(x_train, dtype=np.uint8)\n",
    "        y_train = np.array(y_train, dtype=np.uint8)\n",
    "        x_train = x_train.reshape(x_train.shape[0], color_type, img_rows, img_cols)\n",
    "        y_train = np_utils.to_categorical(y_train, 10)\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_train /= 255\n",
    "        print('Train shape:', x_train.shape)\n",
    "        print(x_train.shape[0], 'train samples')\n",
    "        return x_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def read_and_normalize_manual_test_data(self, img_rows, img_cols, color_type=1):\n",
    "        cache_path = os.path.join('cache', 'test_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "        if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "            test_data = self.load_manual_test(img_rows, img_cols, color_type)\n",
    "            self.cache_data((test_data), cache_path)\n",
    "        else:\n",
    "            print('Restore test from cache!')\n",
    "            (test_data, test_id) = restore_data(cache_path)\n",
    "\n",
    "        test_data = np.array(test_data, dtype=np.uint8)\n",
    "        test_data = test_data.reshape(test_data.shape[0], color_type, img_rows, img_cols)\n",
    "        test_data = test_data.astype('float32')\n",
    "        test_data /= 255\n",
    "        print('Test shape:', test_data.shape)\n",
    "        print(test_data.shape[0], 'test samples')\n",
    "        return test_data\n",
    "    \n",
    "    def load_train(self, img_rows, img_cols, color_type=1):\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        driver_id = []\n",
    "\n",
    "        driver_data = self.get_driver_data()\n",
    "\n",
    "        print('Read train images')\n",
    "        for j in range(10):\n",
    "            print('Load folder c{}'.format(j))\n",
    "            path = os.path.join('..', 'input', 'train', 'c' + str(j), '*.jpg')\n",
    "            files = glob.glob(path)\n",
    "            for fl in files:\n",
    "                flbase = os.path.basename(fl)\n",
    "                img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "                X_train.append(img)\n",
    "                y_train.append(j)\n",
    "                driver_id.append(driver_data[flbase])\n",
    "\n",
    "        unique_drivers = sorted(list(set(driver_id)))\n",
    "        print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "        print(unique_drivers)\n",
    "        return X_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def load_manual_test(self, img_rows, img_cols, color_type=1):\n",
    "        print('Read manual test images')\n",
    "        path = os.path.join('..', 'input', 'test', '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        X_test = []\n",
    "        total = 0\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "            X_test.append(img)\n",
    "            total += 1\n",
    "        return X_test\n",
    "    \n",
    "    def cache_data(self, data, path):\n",
    "        if os.path.isdir(os.path.dirname(path)):\n",
    "            file = open(path, 'wb')\n",
    "            pickle.dump(data, file)\n",
    "            file.close()\n",
    "        else:\n",
    "            print('Directory doesnt exists')\n",
    "    \n",
    "    def get_driver_data(self):\n",
    "        dr = dict()\n",
    "        path = os.path.join('..', 'input', 'driver_imgs_list.csv')\n",
    "        print('Read drivers data')\n",
    "        f = open(path, 'r')\n",
    "        line = f.readline()\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == '':\n",
    "                break\n",
    "            arr = line.strip().split(',')\n",
    "            dr[arr[2]] = arr[0]\n",
    "        f.close()\n",
    "        return dr\n",
    "    \n",
    "    def get_image(self, path, img_rows, img_cols, color_type=1):\n",
    "        # Load as grayscale\n",
    "        if color_type == 1:\n",
    "            img = cv2.imread(path, 0)\n",
    "        elif color_type == 3:\n",
    "            img = cv2.imread(path)\n",
    "        return cv2.resize(img, (img_cols, img_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(im):\n",
    "    vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "    #im = cv2.resize(cv2.imread(path), (224, 224)).astype(np.float32)\n",
    "    im = (im - vgg_mean)\n",
    "    return im[:, ::-1] # RGB to BGR\n",
    "\n",
    "def create_vgg16(img_rows, img_cols, color_type=1, num_classes=None):\n",
    "    # we initialize the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Conv Block 1\n",
    "    model.add(Lambda(preprocess_image, input_shape=(img_rows,img_cols,color_type), output_shape=(img_rows,img_cols,color_type)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), input_shape=(img_rows,img_cols,color_type), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Conv Block 2\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Conv Block 3\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Conv Block 4\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Conv Block 5\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # FC layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    \n",
    "    model.load_weights('models/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    model.layers.pop()\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "    model.layers[-1].outbound_nodes = []\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Uncomment below to set the first 10 layers to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers[:10]:\n",
    "       layer.trainable = False\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=10e-5)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'], )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues, filename=None):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    if not filename == None:\n",
    "        plt.savefig(filename)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 224\n",
    "img_cols = 224\n",
    "color_type = 3\n",
    "\n",
    "batch_size = 32\n",
    "nb_epoch = 5\n",
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read drivers data\n",
      "Read train images\n",
      "Load folder c0\n",
      "Load folder c1\n",
      "Load folder c2\n",
      "Load folder c3\n",
      "Load folder c4\n",
      "Load folder c5\n",
      "Load folder c6\n",
      "Load folder c7\n",
      "Load folder c8\n",
      "Load folder c9\n",
      "Unique drivers: 26\n",
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "Directory doesnt exists\n",
      "('Train shape:', (22424, 3, 224, 224))\n",
      "(22424, 'train samples')\n",
      "(15024, 10)\n",
      "(7400, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "ddh = DriverDistractionHelper(img_rows, img_cols, color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print Counter(np.argmax(ddh.y_test, axis=1))\n",
    "print Counter(np.argmax(ddh.y_val, axis=1))\n",
    "print Counter(np.argmax(ddh.y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = create_vgg16(img_rows, img_cols, color_type, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['safe driving', 'texting - right', 'talking on the phone - right', 'exting - left', 'talking on the phone - left',\n",
    "          'operating the radio', 'drinking', 'reaching behind', 'hair and makeup', 'talking to passenger']\n",
    "keys = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y_test = np.argmax(ddh.y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15024 samples, validate on 7400 samples\n",
      "Epoch 1/5\n",
      " 4160/15024 [=======>......................] - ETA: 2:18:31 - loss: 2.3143 - acc: 0.1075"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    model.fit(ddh.x_train, ddh.y_train, batch_size=batch_size, epochs=5, verbose=1, validation_data=(ddh.x_val, ddh.y_val))\n",
    "    scores = model.evaluate(x=ddh.x_test, y=ddh.y_test, batch_size=128)\n",
    "    print 'Metrics: ', scores\n",
    "    y_pred_test = model.predict(ddh.x_test, batch_size=128, verbose=1)\n",
    "    y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(true_y_test, y_pred_test)\n",
    "    plot_confusion_matrix(cm, keys, normalize=False, filename='cm_epoch_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/vgg16_model.h5')\n",
    "model.save_weights('models/vgg16_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

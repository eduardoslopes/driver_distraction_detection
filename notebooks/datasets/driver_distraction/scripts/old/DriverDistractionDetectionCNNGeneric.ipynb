{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "\n",
    "from keras import backend\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Conv2D, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriverDistractionHelper:\n",
    "    \n",
    "    def __init__(self, img_rows, img_cols, color_type=1):\n",
    "        x_train, y_train, driver_id, unique_drivers = self.read_and_normalize_train_data(img_rows, img_cols, color_type)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.33, shuffle=True)\n",
    "        \n",
    "        x_manual_tests = self.read_and_normalize_manual_test_data(120, 160, color_type)\n",
    "        \n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.x_manual_tests = x_manual_tests\n",
    "    \n",
    "    def read_and_normalize_train_data(self, img_rows, img_cols, color_type):\n",
    "        cache_path = os.path.join('cache', 'train_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "        if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "            x_train, y_train, driver_id, unique_drivers = self.load_train(img_rows, img_cols, color_type)\n",
    "            self.cache_data((x_train, y_train, driver_id, unique_drivers), cache_path)\n",
    "        else:\n",
    "            print('Restore train from cache!')\n",
    "            (x_train, train_target, driver_id, unique_drivers) = restore_data(cache_path)\n",
    "\n",
    "        x_train = np.array(x_train, dtype=np.uint8)\n",
    "        y_train = np.array(y_train, dtype=np.uint8)\n",
    "        x_train = x_train.reshape(x_train.shape[0], color_type, img_rows, img_cols)\n",
    "        y_train = np_utils.to_categorical(y_train, 10)\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_train /= 255\n",
    "        print('Train shape:', x_train.shape)\n",
    "        print(x_train.shape[0], 'train samples')\n",
    "        return x_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def read_and_normalize_manual_test_data(self, img_rows, img_cols, color_type=1):\n",
    "        cache_path = os.path.join('cache', 'test_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "        if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "            test_data = self.load_manual_test(img_rows, img_cols, color_type)\n",
    "            self.cache_data((test_data), cache_path)\n",
    "        else:\n",
    "            print('Restore test from cache!')\n",
    "            (test_data, test_id) = restore_data(cache_path)\n",
    "\n",
    "        test_data = np.array(test_data, dtype=np.uint8)\n",
    "        test_data = test_data.reshape(test_data.shape[0], color_type, img_rows, img_cols)\n",
    "        test_data = test_data.astype('float32')\n",
    "        test_data /= 255\n",
    "        print('Test shape:', test_data.shape)\n",
    "        print(test_data.shape[0], 'test samples')\n",
    "        return test_data\n",
    "    \n",
    "    def load_train(self, img_rows, img_cols, color_type=1):\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        driver_id = []\n",
    "\n",
    "        driver_data = self.get_driver_data()\n",
    "\n",
    "        print('Read train images')\n",
    "        for j in range(10):\n",
    "            print('Load folder c{}'.format(j))\n",
    "            path = os.path.join('..', 'input', 'train', 'c' + str(j), '*.jpg')\n",
    "            files = glob.glob(path)\n",
    "            for fl in files:\n",
    "                flbase = os.path.basename(fl)\n",
    "                img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "                X_train.append(img)\n",
    "                y_train.append(j)\n",
    "                driver_id.append(driver_data[flbase])\n",
    "\n",
    "        unique_drivers = sorted(list(set(driver_id)))\n",
    "        print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "        print(unique_drivers)\n",
    "        return X_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def load_manual_test(self, img_rows, img_cols, color_type=1):\n",
    "        print('Read manual test images')\n",
    "        path = os.path.join('..', 'input', 'test', '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        X_test = []\n",
    "        total = 0\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "            X_test.append(img)\n",
    "            total += 1\n",
    "        return X_test\n",
    "    \n",
    "    def cache_data(self, data, path):\n",
    "        if os.path.isdir(os.path.dirname(path)):\n",
    "            file = open(path, 'wb')\n",
    "            pickle.dump(data, file)\n",
    "            file.close()\n",
    "        else:\n",
    "            print('Directory doesnt exists')\n",
    "    \n",
    "    def get_driver_data(self):\n",
    "        dr = dict()\n",
    "        path = os.path.join('..', 'input', 'driver_imgs_list.csv')\n",
    "        print('Read drivers data')\n",
    "        f = open(path, 'r')\n",
    "        line = f.readline()\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == '':\n",
    "                break\n",
    "            arr = line.strip().split(',')\n",
    "            dr[arr[2]] = arr[0]\n",
    "        f.close()\n",
    "        return dr\n",
    "    \n",
    "    def get_image(self, path, img_rows, img_cols, color_type=1):\n",
    "        # Load as grayscale\n",
    "        if color_type == 1:\n",
    "            img = cv2.imread(path, 0)\n",
    "        elif color_type == 3:\n",
    "            img = cv2.imread(path)\n",
    "        return cv2.resize(img, (img_cols, img_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_rows, img_cols, color_type=1):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 48\n",
    "img_cols = 64\n",
    "color_type = 3\n",
    "\n",
    "batch_size = 32\n",
    "nb_epoch = 20\n",
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddh = DriverDistractionHelper(img_rows, img_cols, color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = create_model(img_rows, img_cols, color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_before_training = datetime.now()\n",
    "model.fit(ddh.x_train, ddh.y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
    "time_after_training = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before_pred = datetime.now()\n",
    "predictions_valid = model.predict(ddh.x_test, batch_size=128, verbose=1)\n",
    "time_after_pred = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time = time_after_training - time_before_training\n",
    "training_time = training_time.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_time = time_after_pred - time_before_pred\n",
    "pred_time_avg = (pred_time.total_seconds()*1000)/len(ddh.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    pure_y_valid = backend.argmax(ddh.y_test)\n",
    "    pure_y_pred = backend.argmax(predictions_valid)\n",
    "\n",
    "    \n",
    "    pure_y_valid = sess.run(pure_y_valid)\n",
    "    pure_y_pred = sess.run(pure_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_comp = [1 if i==j else 0 for i,j in zip(pure_y_pred, pure_y_valid)]\n",
    "accuracy = np.mean(y_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Accuracy: ', accuracy\n",
    "print 'Training Time: ', training_time\n",
    "print 'Average Time to Classify a Image: ', pred_time_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(pure_y_valid, pure_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['safe driving', 'texting - right', 'talking on the phone - right', 'exting - left', 'talking on the phone - left',\n",
    "          'operating the radio', 'drinking', 'reaching behind', 'hair and makeup', 'talking to passenger']\n",
    "keys = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, keys, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(100):\n",
    "#    img_brute = ddh.x_manual_tests[i]\n",
    "#    img = img_brute.transpose(1, 2, 0)\n",
    "#    img = cv2.resize(img, (img_cols, img_rows))\n",
    "#    img = img.reshape(1, 1, img_rows, img_cols)\n",
    "#    predicted = model.predict_classes(img)\n",
    "        \n",
    "#    plt.figure()\n",
    "#    plt.title(predicted)\n",
    "#    plt.imshow(img_brute.reshape(120, 160), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

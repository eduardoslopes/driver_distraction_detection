{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras import backend\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers import Conv2D, Input, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n",
    "from keras.applications import InceptionV3\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriverDistractionHelper:\n",
    "    \n",
    "    def __init__(self, img_rows, img_cols, color_type=1):\n",
    "        pass\n",
    "#         x_train, y_train, driver_id, unique_drivers = self.read_and_normalize_train_data(img_rows, img_cols, color_type)\n",
    "#         x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, shuffle=True)\n",
    "        \n",
    "#         x_manual_tests = self.read_and_normalize_manual_test_data(120, 160, color_type)\n",
    "        \n",
    "#         self.x_train = x_train\n",
    "#         self.y_train = y_train\n",
    "#         self.x_test = x_test\n",
    "#         self.y_test = y_test\n",
    "        \n",
    "#         self.x_manual_tests = x_manual_tests\n",
    "    \n",
    "    def read_and_normalize_train_data(self, img_rows, img_cols, color_type):\n",
    "        x_train, y_train, driver_id, unique_drivers = self.load_train(img_rows, img_cols, color_type)\n",
    "        x_train = np.array(x_train, dtype=np.uint8)\n",
    "        y_train = np.array(y_train, dtype=np.uint8)\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, color_type)\n",
    "        y_train = np_utils.to_categorical(y_train, 10)\n",
    "        \n",
    "        print('Train shape:', x_train.shape)\n",
    "        print(x_train.shape[0], 'train samples')\n",
    "        return x_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def read_and_normalize_test_data(self, begin_index, img_rows, img_cols, color_type=1, count=1000):\n",
    "        test_data, test_ids = self.load_test(begin_index, img_rows, img_cols, color_type, count)\n",
    "\n",
    "        test_data = np.array(test_data, dtype=np.uint8)\n",
    "        test_data = test_data.reshape(test_data.shape[0], img_rows, img_cols, color_type)\n",
    "        \n",
    "        print('Test shape:', test_data.shape)\n",
    "        print(test_data.shape[0], 'test samples')\n",
    "        return test_data, test_ids\n",
    "    \n",
    "    def load_train(self, img_rows, img_cols, color_type=1):\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        driver_id = []\n",
    "\n",
    "        driver_data = self.get_driver_data()\n",
    "\n",
    "        print('Read train images')\n",
    "        for j in range(10):\n",
    "            print('Load folder c{}'.format(j))\n",
    "            path = os.path.join('..', 'input', 'train', 'c' + str(j), '*.jpg')\n",
    "            files = glob.glob(path)\n",
    "            for fl in files:\n",
    "                flbase = os.path.basename(fl)\n",
    "                img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "                X_train.append(img)\n",
    "                y_train.append(j)\n",
    "                driver_id.append(driver_data[flbase])\n",
    "\n",
    "        unique_drivers = sorted(list(set(driver_id)))\n",
    "        print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "        print(unique_drivers)\n",
    "        return X_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def load_test(self, begin_index, img_rows, img_cols, color_type=1, count=1000):\n",
    "        print('Read manual test images')\n",
    "        path = os.path.join('..', 'input', 'test', '*.jpg')\n",
    "        files = sorted(glob.glob(path))\n",
    "        \n",
    "        if(len(files)-count < begin_index):\n",
    "            files = files[begin_index : len(files)]\n",
    "        else:\n",
    "            files = files[begin_index : begin_index+count]\n",
    "\n",
    "        X_test = []\n",
    "        X_test_id = []\n",
    "        total = 0\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "            X_test.append(img)\n",
    "            X_test_id.append(flbase)\n",
    "            total += 1\n",
    "        return X_test, X_test_id\n",
    "    \n",
    "    def cache_data(self, data, path):\n",
    "        if os.path.isdir(os.path.dirname(path)):\n",
    "            file = open(path, 'wb')\n",
    "            pickle.dump(data, file)\n",
    "            file.close()\n",
    "        else:\n",
    "            print('Directory doesnt exists')\n",
    "    \n",
    "    def get_driver_data(self):\n",
    "        dr = dict()\n",
    "        path = os.path.join('..', 'input', 'driver_imgs_list.csv')\n",
    "        print('Read drivers data')\n",
    "        f = open(path, 'r')\n",
    "        line = f.readline()\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == '':\n",
    "                break\n",
    "            arr = line.strip().split(',')\n",
    "            dr[arr[2]] = arr[0]\n",
    "        f.close()\n",
    "        return dr\n",
    "    \n",
    "    def get_image(self, path, img_rows, img_cols, color_type=1):        \n",
    "        # Load as grayscale\n",
    "        if color_type == 1:\n",
    "            img = image.load_img(path, grayscale=True, target_size=(img_rows, img_cols))\n",
    "        elif color_type == 3:\n",
    "            img = image.load_img(path, target_size=(img_rows, img_cols))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = self.preprocess_input(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def preprocess_input(self, img):\n",
    "        img /= 255.\n",
    "        img -= 0.5\n",
    "        img *= 2.\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_bn(x, nb_filter, nb_row, nb_col,\n",
    "              padding='same', subsample=(1, 1),\n",
    "              name=None):\n",
    "    \"\"\"\n",
    "    Utility function to apply conv + BN for Inception V3.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    bn_axis = 3\n",
    "    x = Conv2D(nb_filter, (nb_row, nb_col),\n",
    "                      strides=subsample,\n",
    "                      activation='relu',\n",
    "                      padding=padding,\n",
    "                      name=conv_name, \n",
    "                      data_format='channels_last')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name)(x)\n",
    "    return x\n",
    "\n",
    "def create_model(img_rows, img_cols, color_type=1, num_classes=10):\n",
    "    channel_axis = 3\n",
    "    img_input = Input(shape=(img_rows, img_cols, color_type))\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, subsample=(2, 2), padding='valid')\n",
    "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv2d_bn(x, 80, 1, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 192, 3, 3, padding='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    for i in range(3):\n",
    "        branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "        branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "        x = concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "                  axis=channel_axis,\n",
    "                  name='mixed' + str(i))\n",
    "\n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, subsample=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3,\n",
    "                             subsample=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = concatenate([branch3x3, branch3x3dbl, branch_pool],\n",
    "              axis=channel_axis,\n",
    "              name='mixed3')\n",
    "\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "              axis=channel_axis,\n",
    "              name='mixed4')\n",
    "\n",
    "    # mixed 5, 6: 17 x 17 x 768\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "                  axis=channel_axis,\n",
    "                  name='mixed' + str(5 + i))\n",
    "\n",
    "    # mixed 7: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "              axis=channel_axis,\n",
    "              name='mixed7')\n",
    "\n",
    "    # mixed 8: 8 x 8 x 1280\n",
    "    branch3x3 = conv2d_bn(x, 192, 1, 1, subsample=(1, 1), padding='same')\n",
    "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
    "                          subsample=(2, 2), padding='valid')\n",
    "\n",
    "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 3, 3,\n",
    "                            subsample=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = concatenate([branch3x3, branch7x7x3, branch_pool],\n",
    "              axis=channel_axis,\n",
    "              name='mixed8')\n",
    "\n",
    "    # mixed 9: 8 x 8 x 2048\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = concatenate([branch3x3_1, branch3x3_2],\n",
    "                          axis=channel_axis,\n",
    "                          name='mixed9_' + str(i))\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = concatenate([branch3x3dbl_1, branch3x3dbl_2],\n",
    "                             axis=channel_axis)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "                  axis=channel_axis,\n",
    "                  name='mixed' + str(9 + i))\n",
    "\n",
    "    # Fully Connected Softmax Layer\n",
    "    x_fc = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)\n",
    "    x_fc = Flatten(name='flatten')(x_fc)\n",
    "    x_fc = Dense(1000, activation='softmax', name='predictions')(x_fc)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x_fc)\n",
    "\n",
    "    # Load ImageNet pre-trained data \n",
    "    model.load_weights('models/inception_v3_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    # Cannot use model.layers.pop() since model is not of Sequential() type\n",
    "    # The method below works since pre-trained weights are stored in layers but not in the model\n",
    "    x_newfc = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)\n",
    "    x_newfc = Flatten(name='flatten')(x_newfc)\n",
    "    x_newfc = Dense(num_classes, activation='softmax', name='predictions')(x_newfc)\n",
    "\n",
    "    # Create another model with our customized softmax\n",
    "    model = Model(img_input, x_newfc)\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 299\n",
    "img_cols = 299\n",
    "color_type = 3\n",
    "\n",
    "batch_size = 32\n",
    "nb_epoch = 4\n",
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read drivers data\n",
      "Read train images\n",
      "Load folder c0\n",
      "Load folder c1\n",
      "Load folder c2\n",
      "Load folder c3\n",
      "Load folder c4\n",
      "Load folder c5\n",
      "Load folder c6\n",
      "Load folder c7\n",
      "Load folder c8\n",
      "Load folder c9\n",
      "Unique drivers: 26\n",
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "('Train shape:', (22424, 299, 299, 3))\n",
      "(22424, 'train samples')\n"
     ]
    }
   ],
   "source": [
    "ddh = DriverDistractionHelper(img_rows, img_cols, color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = create_model(img_rows, img_cols, color_type)\n",
    "# model = create_model_keras(300, 300, color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17939 samples, validate on 4485 samples\n",
      "Epoch 1/4\n",
      "17939/17939 [==============================] - 14017s 781ms/step - loss: 0.9774 - acc: 0.6756 - val_loss: 0.2359 - val_acc: 0.9315\n",
      "Epoch 2/4\n",
      "17939/17939 [==============================] - 14003s 781ms/step - loss: 0.0842 - acc: 0.9788 - val_loss: 0.1354 - val_acc: 0.9567\n",
      "Epoch 3/4\n",
      "17939/17939 [==============================] - 14000s 780ms/step - loss: 0.0177 - acc: 0.9970 - val_loss: 0.0726 - val_acc: 0.9784\n",
      "Epoch 4/4\n",
      "17939/17939 [==============================] - 13970s 779ms/step - loss: 0.0070 - acc: 0.9994 - val_loss: 0.0574 - val_acc: 0.9842\n"
     ]
    }
   ],
   "source": [
    "time_before_training = datetime.now()\n",
    "model.fit(ddh.x_train, ddh.y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(ddh.x_test, ddh.y_test))\n",
    "time_after_training = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4485/4485 [==============================] - 1153s 257ms/step\n"
     ]
    }
   ],
   "source": [
    "time_before_pred = datetime.now()\n",
    "predictions_valid = model.predict(ddh.x_test, batch_size=128, verbose=1)\n",
    "time_after_pred = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time = time_after_training - time_before_training\n",
    "training_time = training_time.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_time = time_after_pred - time_before_pred\n",
    "pred_time_avg = (pred_time.total_seconds()*1000)/len(ddh.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    pure_y_valid = backend.argmax(ddh.y_test)\n",
    "    pure_y_pred = backend.argmax(predictions_valid)\n",
    "\n",
    "    \n",
    "    pure_y_valid = sess.run(pure_y_valid)\n",
    "    pure_y_pred = sess.run(pure_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_comp = [1 if i==j else 0 for i,j in zip(pure_y_pred, pure_y_valid)]\n",
    "accuracy = np.mean(y_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.984169453735\n",
      "Training Time:  55996.696352\n",
      "Average Time to Classify a Image:  257.074264883\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy: ', accuracy\n",
    "print 'Training Time: ', training_time\n",
    "print 'Average Time to Classify a Image: ', pred_time_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(pure_y_valid, pure_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['safe driving', 'texting - right', 'talking on the phone - right', 'exting - left', 'talking on the phone - left',\n",
    "          'operating the radio', 'drinking', 'reaching behind', 'hair and makeup', 'talking to passenger']\n",
    "keys = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8e1f2cfd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, keys, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(100):\n",
    "#    img_brute = ddh.x_manual_tests[i]\n",
    "#    img = img_brute.transpose(1, 2, 0)\n",
    "#    img = cv2.resize(img, (img_cols, img_rows))\n",
    "#    img = img.reshape(1, 1, img_rows, img_cols)\n",
    "#    predicted = model.predict_classes(img)\n",
    "        \n",
    "#    plt.figure()\n",
    "#    plt.title(predicted)\n",
    "#    plt.imshow(img_brute.reshape(120, 160), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/InceptionV3_model.h5')\n",
    "model.save_weights('models/InceptionV3_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_and_generate_submission(model, driver_distraction_helper, img_rows, img_cols, color_type):\n",
    "    test_imgs, test_ids = driver_distraction_helper.read_and_normalize_test_data(0, img_rows, img_cols, color_type, 1000)\n",
    "\n",
    "    predictions = model.predict(test_imgs, batch_size=128, verbose=1)\n",
    "    \n",
    "    general_result = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    general_result.loc[:, 'img'] = pd.Series(test_ids, index=general_result.index)\n",
    "    \n",
    "    for i in range(80):\n",
    "        test_imgs, test_ids = driver_distraction_helper.read_and_normalize_test_data(((i+1)*1000), img_rows, img_cols, color_type)\n",
    "\n",
    "        predictions = model.predict(test_imgs, batch_size=128, verbose=1)\n",
    "        \n",
    "        result = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "        result.loc[:, 'img'] = pd.Series(test_ids, index=result.index)\n",
    "        \n",
    "        general_result = general_result.append(result, ignore_index=True)\n",
    "        \n",
    "    now = datetime.now()\n",
    "    if not os.path.isdir('subm'):\n",
    "        os.mkdir('subm')\n",
    "    suffix = '_at_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n",
    "    general_result.to_csv(sub_file, index=False, float_format='%.10f')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddh2 = DriverDistractionHelper(img_rows, img_cols, color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 259s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 259s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 259s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 256s 256ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 256s 256ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 259s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 260s 260ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 259s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 260s 260ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 259s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 259s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 260s 260ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 260s 260ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 260s 260ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 259s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 259s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 257s 257ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 258s 258ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (1000, 299, 299, 3))\n",
      "(1000, 'test samples')\n",
      "1000/1000 [==============================] - 260s 260ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (736, 299, 299, 3))\n",
      "(736, 'test samples')\n",
      "736/736 [==============================] - 190s 259ms/step\n",
      "Read manual test images\n",
      "('Test shape:', (0, 299, 299, 3))\n",
      "(0, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "test_model_and_generate_submission(model, ddh2, img_rows, img_cols, color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def read_img(img_id, train_or_test, size, class_id):\n",
    "    \"\"\"Read and resize image.\n",
    "    # Arguments\n",
    "        img_id: string\n",
    "        train_or_test: string 'train' or 'test'.\n",
    "        size: resize the original image.\n",
    "        class_id: class_id\n",
    "    # Returns\n",
    "        Image as numpy array.\n",
    "    \"\"\"\n",
    "    if train_or_test == 'train':\n",
    "        img = image.load_img(os.path.join('../input', train_or_test, '%s' % class_id, '%s' % img_id), target_size=size)\n",
    "    else :\n",
    "        img = image.load_img(os.path.join('../input', train_or_test, '%s' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing............\n",
      "79726\n",
      "0\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "8\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "10\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "11\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "12\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "13\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "14\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "15\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "16\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "17\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "18\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "19\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "20\n",
      "1/1 [==============================] - 0s 263ms/step\n"
     ]
    }
   ],
   "source": [
    "print('Start testing............')\n",
    "test = pd.read_csv('../input/sample_submission.csv')\n",
    "test_labels = test.reset_index()\n",
    "print(len(test))\n",
    "\n",
    "with open('submission_InceptionV3_t2.csv','wb') as file:\n",
    "    file.write('img,'+'c0,c1,c2,c3,c4,c5,c6,c7,c8,c9')\n",
    "    file.write('\\n')\n",
    "\n",
    "    #x_test = np.zeros((len(test), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32') #xx images with 224X224X3\n",
    "    for i, index in enumerate(test_labels['index']):\n",
    "        img_name = test_labels.img[i]\n",
    "        classname = 'c0'\n",
    "        img = read_img(img_name, 'test', (img_rows, img_cols), classname)\n",
    "        x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "        #x_test[i] = x\n",
    "        print i\n",
    "        test_prediction = model.predict(x, batch_size=128, verbose=1)\n",
    "        file.write(img_name+','+str(test_prediction[0][0])+','+str(test_prediction[0][1])+','+str(test_prediction[0][2])+','+str(test_prediction[0][3])\n",
    "                  +','+str(test_prediction[0][4])+','+str(test_prediction[0][5])+','+str(test_prediction[0][6])+','+str(test_prediction[0][7])\n",
    "                  +','+str(test_prediction[0][8])+','+str(test_prediction[0][9]))\n",
    "        file.write('\\n')\n",
    "        \n",
    "        if i == 20:\n",
    "            break\n",
    "\n",
    "    #print('Test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

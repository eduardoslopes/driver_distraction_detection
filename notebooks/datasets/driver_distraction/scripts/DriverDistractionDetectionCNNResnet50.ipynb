{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras import backend\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers import Conv2D, Input, concatenate, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n",
    "from keras.applications import InceptionV3\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriverDistractionHelper:\n",
    "    \n",
    "    def __init__(self, img_rows, img_cols, color_type=1):\n",
    "        x_train, y_train, driver_id, unique_drivers = self.read_and_normalize_train_data(img_rows, img_cols, color_type)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=4484, random_state=57, stratify=y_train)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=4484, random_state=57, stratify=y_train)\n",
    "        \n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "            \n",
    "    def read_and_normalize_train_data(self, img_rows, img_cols, color_type):\n",
    "        x_train, y_train, driver_id, unique_drivers = self.load_train(img_rows, img_cols, color_type)\n",
    "        x_train = np.array(x_train, dtype=np.uint8)\n",
    "        y_train = np.array(y_train, dtype=np.uint8)\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, color_type)\n",
    "        y_train = np_utils.to_categorical(y_train, 10)\n",
    "        \n",
    "        print('Train shape:', x_train.shape)\n",
    "        print(x_train.shape[0], 'train samples')\n",
    "        return x_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def read_and_normalize_test_data(self, begin_index, img_rows, img_cols, color_type=1, count=1000):\n",
    "        test_data, test_ids = self.load_test(begin_index, img_rows, img_cols, color_type, count)\n",
    "\n",
    "        test_data = np.array(test_data, dtype=np.uint8)\n",
    "        test_data = test_data.reshape(test_data.shape[0], img_rows, img_cols, color_type)\n",
    "        \n",
    "        print('Test shape:', test_data.shape)\n",
    "        print(test_data.shape[0], 'test samples')\n",
    "        return test_data, test_ids\n",
    "    \n",
    "    def load_train(self, img_rows, img_cols, color_type=1):\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        driver_id = []\n",
    "\n",
    "        driver_data = self.get_driver_data()\n",
    "\n",
    "        print('Read train images')\n",
    "        for j in range(10):\n",
    "            print('Load folder c{}'.format(j))\n",
    "            path = os.path.join('..', 'input', 'train', 'c' + str(j), '*.jpg')\n",
    "            files = glob.glob(path)\n",
    "            for fl in files:\n",
    "                flbase = os.path.basename(fl)\n",
    "                img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "                X_train.append(img)\n",
    "                y_train.append(j)\n",
    "                driver_id.append(driver_data[flbase])\n",
    "\n",
    "        unique_drivers = sorted(list(set(driver_id)))\n",
    "        print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "        print(unique_drivers)\n",
    "        return X_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def load_test(self, begin_index, img_rows, img_cols, color_type=1, count=1000):\n",
    "        print('Read manual test images')\n",
    "        path = os.path.join('..', 'input', 'test', '*.jpg')\n",
    "        files = sorted(glob.glob(path))\n",
    "        \n",
    "        if(len(files)-count < begin_index):\n",
    "            files = files[begin_index : len(files)]\n",
    "        else:\n",
    "            files = files[begin_index : begin_index+count]\n",
    "\n",
    "        X_test = []\n",
    "        X_test_id = []\n",
    "        total = 0\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "            X_test.append(img)\n",
    "            X_test_id.append(flbase)\n",
    "            total += 1\n",
    "        return X_test, X_test_id\n",
    "    \n",
    "    def cache_data(self, data, path):\n",
    "        if os.path.isdir(os.path.dirname(path)):\n",
    "            file = open(path, 'wb')\n",
    "            pickle.dump(data, file)\n",
    "            file.close()\n",
    "        else:\n",
    "            print('Directory doesnt exists')\n",
    "    \n",
    "    def get_driver_data(self):\n",
    "        dr = dict()\n",
    "        path = os.path.join('..', 'input', 'driver_imgs_list.csv')\n",
    "        print('Read drivers data')\n",
    "        f = open(path, 'r')\n",
    "        line = f.readline()\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == '':\n",
    "                break\n",
    "            arr = line.strip().split(',')\n",
    "            dr[arr[2]] = arr[0]\n",
    "        f.close()\n",
    "        return dr\n",
    "    \n",
    "    def get_image(self, path, img_rows, img_cols, color_type=1):        \n",
    "        # Load as grayscale\n",
    "        if color_type == 1:\n",
    "            img = image.load_img(path, grayscale=True, target_size=(img_rows, img_cols))\n",
    "        elif color_type == 3:\n",
    "            img = image.load_img(path, target_size=(img_rows, img_cols))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = self.preprocess_input(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def preprocess_input(self, img):\n",
    "        img /= 255.\n",
    "        img -= 0.5\n",
    "        img *= 2.\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"\n",
    "    The identity_block is the block that has no conv layer at shortcut\n",
    "    Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    \"\"\"\n",
    "\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter2, (kernel_size, kernel_size),\n",
    "                      padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"\n",
    "    conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    \"\"\"\n",
    "\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(nb_filter1, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter2, (kernel_size, kernel_size), padding='same',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(nb_filter3, (1, 1), strides=strides,\n",
    "                             name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_model(img_rows, img_cols, color_type=1, num_classes=None):\n",
    "    \"\"\"\n",
    "    Resnet 50 Model for Keras\n",
    "    Model Schema is based on \n",
    "    https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n",
    "    ImageNet Pretrained Weights \n",
    "    https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels.h5\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of class labels for our classification task\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle Dimension Ordering for different backends\n",
    "    global bn_axis\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "      bn_axis = 3\n",
    "      img_input = Input(shape=(img_rows, img_cols, color_type))\n",
    "    else:\n",
    "      bn_axis = 1\n",
    "      img_input = Input(shape=(color_type, img_rows, img_cols))\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # Fully Connected Softmax Layer\n",
    "    x_fc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    x_fc = Flatten()(x_fc)\n",
    "    x_fc = Dense(1000, activation='softmax', name='fc1000')(x_fc)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x_fc)\n",
    "\n",
    "    weights_path = 'models/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    # Cannot use model.layers.pop() since model is not of Sequential() type\n",
    "    # The method below works since pre-trained weights are stored in layers but not in the model\n",
    "    x_newfc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    x_newfc = Flatten()(x_newfc)\n",
    "    x_newfc = Dense(num_classes, activation='softmax', name='fc10')(x_newfc)\n",
    "\n",
    "    # Create another model with our customized softmax\n",
    "    model = Model(img_input, x_newfc)\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues, filename=None):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    if not filename == None:\n",
    "        plt.savefig(filename)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 224\n",
    "img_cols = 224\n",
    "color_type = 3\n",
    "\n",
    "batch_size = 32\n",
    "nb_epoch = 4\n",
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read drivers data\n",
      "Read train images\n",
      "Load folder c0\n",
      "Load folder c1\n",
      "Load folder c2\n",
      "Load folder c3\n",
      "Load folder c4\n",
      "Load folder c5\n",
      "Load folder c6\n",
      "Load folder c7\n",
      "Load folder c8\n",
      "Load folder c9\n",
      "Unique drivers: 26\n",
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "('Train shape:', (22424, 299, 299, 3))\n",
      "(22424, 'train samples')\n"
     ]
    }
   ],
   "source": [
    "ddh = DriverDistractionHelper(img_rows, img_cols, color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print Counter(np.argmax(ddh.y_test, axis=1))\n",
    "print Counter(np.argmax(ddh.y_val, axis=1))\n",
    "print Counter(np.argmax(ddh.y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = create_model(img_rows=img_rows, img_cols=img_cols, color_type=color_type, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['safe driving', 'texting - right', 'talking on the phone - right', 'exting - left', 'talking on the phone - left',\n",
    "          'operating the radio', 'drinking', 'reaching behind', 'hair and makeup', 'talking to passenger']\n",
    "keys = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y_test = np.argmax(ddh.y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17939 samples, validate on 4485 samples\n",
      "Epoch 1/4\n",
      "17939/17939 [==============================] - 14017s 781ms/step - loss: 0.9774 - acc: 0.6756 - val_loss: 0.2359 - val_acc: 0.9315\n",
      "Epoch 2/4\n",
      "17939/17939 [==============================] - 14003s 781ms/step - loss: 0.0842 - acc: 0.9788 - val_loss: 0.1354 - val_acc: 0.9567\n",
      "Epoch 3/4\n",
      "17939/17939 [==============================] - 14000s 780ms/step - loss: 0.0177 - acc: 0.9970 - val_loss: 0.0726 - val_acc: 0.9784\n",
      "Epoch 4/4\n",
      "17939/17939 [==============================] - 13970s 779ms/step - loss: 0.0070 - acc: 0.9994 - val_loss: 0.0574 - val_acc: 0.9842\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    model.fit(ddh.x_train, ddh.y_train, batch_size=batch_size, epochs=5, verbose=1, validation_data=(ddh.x_val, ddh.y_val))\n",
    "    scores = model.evaluate(x=ddh.x_test, y=ddh.y_test, batch_size=128)\n",
    "    print 'Metrics: ', scores\n",
    "    y_pred_test = model.predict(ddh.x_test, batch_size=128, verbose=1)\n",
    "    y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(true_y_test, y_pred_test)\n",
    "    plot_confusion_matrix(cm, keys, normalize=False, filename='cm_epoch_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/resnet50_model.h5')\n",
    "model.save_weights('models/resnet50_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

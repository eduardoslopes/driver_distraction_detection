{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras import backend\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers import Conv2D, Input, concatenate, add, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n",
    "from keras.applications import InceptionV3\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriverDistractionHelper:\n",
    "    \n",
    "    def __init__(self, img_rows, img_cols, color_type=1):\n",
    "        pass\n",
    "        x_train, y_train, driver_id, unique_drivers = self.read_and_normalize_train_data(img_rows, img_cols, color_type)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=4484, random_state=57, stratify=y_train)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=4484, random_state=57, stratify=y_train)\n",
    "        \n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "            \n",
    "    def read_and_normalize_train_data(self, img_rows, img_cols, color_type):\n",
    "        x_train, y_train, driver_id, unique_drivers = self.load_train(img_rows, img_cols, color_type)\n",
    "        x_train = np.array(x_train, dtype=np.uint8)\n",
    "        y_train = np.array(y_train, dtype=np.uint8)\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, color_type)\n",
    "        y_train = np_utils.to_categorical(y_train, 10)\n",
    "        \n",
    "        print('Train shape:', x_train.shape)\n",
    "        print(x_train.shape[0], 'train samples')\n",
    "        return x_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def read_and_normalize_test_data(self, begin_index, img_rows, img_cols, color_type=1, count=1000):\n",
    "        test_data, test_ids = self.load_test(begin_index, img_rows, img_cols, color_type, count)\n",
    "\n",
    "        test_data = np.array(test_data, dtype=np.uint8)\n",
    "        test_data = test_data.reshape(test_data.shape[0], img_rows, img_cols, color_type)\n",
    "        \n",
    "        print('Test shape:', test_data.shape)\n",
    "        print(test_data.shape[0], 'test samples')\n",
    "        return test_data, test_ids\n",
    "    \n",
    "    def load_train(self, img_rows, img_cols, color_type=1):\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        driver_id = []\n",
    "\n",
    "        driver_data = self.get_driver_data()\n",
    "\n",
    "        print('Read train images')\n",
    "        for j in range(10):\n",
    "            print('Load folder c{}'.format(j))\n",
    "            path = os.path.join('..', 'input', 'train', 'c' + str(j), '*.jpg')\n",
    "            files = glob.glob(path)\n",
    "            for fl in files:\n",
    "                flbase = os.path.basename(fl)\n",
    "                img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "                X_train.append(img)\n",
    "                y_train.append(j)\n",
    "                driver_id.append(driver_data[flbase])\n",
    "\n",
    "        unique_drivers = sorted(list(set(driver_id)))\n",
    "        print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "        print(unique_drivers)\n",
    "        return X_train, y_train, driver_id, unique_drivers\n",
    "    \n",
    "    def load_test(self, begin_index, img_rows, img_cols, color_type=1, count=1000):\n",
    "        print('Read manual test images')\n",
    "        path = os.path.join('..', 'input', 'test', '*.jpg')\n",
    "        files = sorted(glob.glob(path))\n",
    "        \n",
    "        if(len(files)-count < begin_index):\n",
    "            files = files[begin_index : len(files)]\n",
    "        else:\n",
    "            files = files[begin_index : begin_index+count]\n",
    "\n",
    "        X_test = []\n",
    "        X_test_id = []\n",
    "        total = 0\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = self.get_image(fl, img_rows, img_cols, color_type)\n",
    "            X_test.append(img)\n",
    "            X_test_id.append(flbase)\n",
    "            total += 1\n",
    "        return X_test, X_test_id\n",
    "    \n",
    "    def cache_data(self, data, path):\n",
    "        if os.path.isdir(os.path.dirname(path)):\n",
    "            file = open(path, 'wb')\n",
    "            pickle.dump(data, file)\n",
    "            file.close()\n",
    "        else:\n",
    "            print('Directory doesnt exists')\n",
    "    \n",
    "    def get_driver_data(self):\n",
    "        dr = dict()\n",
    "        path = os.path.join('..', 'input', 'driver_imgs_list.csv')\n",
    "        print('Read drivers data')\n",
    "        f = open(path, 'r')\n",
    "        line = f.readline()\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == '':\n",
    "                break\n",
    "            arr = line.strip().split(',')\n",
    "            dr[arr[2]] = arr[0]\n",
    "        f.close()\n",
    "        return dr\n",
    "    \n",
    "    def get_image(self, path, img_rows, img_cols, color_type=1):        \n",
    "        # Load as grayscale\n",
    "        if color_type == 1:\n",
    "            img = image.load_img(path, grayscale=True, target_size=(img_rows, img_cols))\n",
    "        elif color_type == 3:\n",
    "            img = image.load_img(path, target_size=(img_rows, img_cols))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = self.preprocess_input(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def preprocess_input(self, img):\n",
    "        img /= 255.\n",
    "        img -= 0.5\n",
    "        img *= 2.\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_rows, img_cols, color_type=1, num_classes=None):\n",
    "    nb_classes = 10\n",
    "    # number of convolutional filters to use\n",
    "    nb_filters = 10\n",
    "    # size of pooling area for max pooling\n",
    "    nb_pool = 2\n",
    "    # convolution kernel size\n",
    "    nb_conv = 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(nb_filters, (nb_conv, nb_conv), padding='valid', input_shape=(img_rows, img_cols, color_type), data_format = 'channels_last' ))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(nb_filters, (nb_conv, nb_conv)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool), data_format=\"channels_last\"))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=0, momentum=0, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues, filename=None):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    if not filename == None:\n",
    "        plt.savefig(filename)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 48\n",
    "img_cols = 64\n",
    "color_type = 1\n",
    "\n",
    "batch_size = 32\n",
    "nb_epoch = 4\n",
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read drivers data\n",
      "Read train images\n",
      "Load folder c0\n",
      "Load folder c1\n",
      "Load folder c2\n",
      "Load folder c3\n",
      "Load folder c4\n",
      "Load folder c5\n",
      "Load folder c6\n",
      "Load folder c7\n",
      "Load folder c8\n",
      "Load folder c9\n",
      "Unique drivers: 26\n",
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "('Train shape:', (22424, 48, 64, 1))\n",
      "(22424, 'train samples')\n"
     ]
    }
   ],
   "source": [
    "ddh = DriverDistractionHelper(img_rows, img_cols, color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 498, 3: 469, 4: 465, 6: 465, 2: 463, 5: 462, 1: 453, 9: 426, 7: 401, 8: 382})\n",
      "Counter({0: 498, 3: 469, 4: 465, 6: 465, 2: 463, 5: 462, 1: 454, 9: 426, 7: 400, 8: 382})\n",
      "Counter({0: 1493, 3: 1408, 4: 1396, 6: 1395, 2: 1391, 5: 1388, 1: 1360, 9: 1277, 7: 1201, 8: 1147})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print Counter(np.argmax(ddh.y_test, axis=1))\n",
    "print Counter(np.argmax(ddh.y_val, axis=1))\n",
    "print Counter(np.argmax(ddh.y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = create_model(img_rows=img_rows, img_cols=img_cols, color_type=color_type, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['safe driving', 'texting - right', 'talking on the phone - right', 'exting - left', 'talking on the phone - left',\n",
    "          'operating the radio', 'drinking', 'reaching behind', 'hair and makeup', 'talking to passenger']\n",
    "keys = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y_test = np.argmax(ddh.y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13456 samples, validate on 4484 samples\n",
      "Epoch 1/1\n",
      "13456/13456 [==============================] - 34s 3ms/step - loss: 14.4402 - acc: 0.1040 - val_loss: 14.4466 - val_acc: 0.1037\n",
      "4484/4484 [==============================] - 3s 768us/step\n",
      "Metrics:  [14.446620832267985, 0.10370205173951828]\n",
      "4484/4484 [==============================] - 3s 766us/step\n",
      "Train on 13456 samples, validate on 4484 samples\n",
      "Epoch 1/1\n",
      "13456/13456 [==============================] - 34s 3ms/step - loss: 14.4459 - acc: 0.1037 - val_loss: 14.4466 - val_acc: 0.1037\n",
      "4484/4484 [==============================] - 3s 780us/step\n",
      "Metrics:  [14.446620832267985, 0.10370205173951828]\n",
      "4484/4484 [==============================] - 3s 745us/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    model.fit(ddh.x_train, ddh.y_train, batch_size=batch_size, epochs=1, verbose=1, validation_data=(ddh.x_val, ddh.y_val))\n",
    "    scores = model.evaluate(x=ddh.x_test, y=ddh.y_test, batch_size=128)\n",
    "    print 'Metrics: ', scores\n",
    "    y_pred_test = model.predict(ddh.x_test, batch_size=128, verbose=1)\n",
    "    y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(true_y_test, y_pred_test)\n",
    "    plot_confusion_matrix(cm, keys, normalize=False, filename='cm_epoch_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/simple_model.h5')\n",
    "model.save_weights('models/simple_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
